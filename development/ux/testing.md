# Usability testing

You give test participants the tasks to do, you observe, and you learn.

## Keeping testing simple - so do enough of it

> Why didn't we do this sooner?

If somebody asked to do usability testing of the site launching in two weeks, when it was almost certainly a request for a disaster check.

If it was two months, then odds were that this was some internal debates about things like aesthetics.

People often test to decide which color drapes are best, only to learn that they forgot to put windows in the room.

This is how a lot of usability testing gets done: too little, too late, and for all the wrong reasons.

## Repeat after me: Focus groups are not usability tests

- In a **focus group**, a small group of people (5 to 10) sit around a table and talk about things, like their opinions about product, their past experience with them, or their reaction to new concepts. Focus groups are good for quickly getting a sampling of users' feelings and opinions about things. This is great to determine audience wants and needs.
- **Usability tests** are about watching one person at a time try to use something (Web site, prototype) to do typical tasks so you can detect and fix the things that confuse or frustrate them.

The main difference is that in usability tests, you watch people actually *use* things, instead of just listening to them talk about them.

Basically, you should use focus groups to get a product idea *before* designing and building the product.

## Several true things about usability testing

- **If you want a great site, you've got to test.** The only way to find out if it really works is to watch other people try to use it.
- **Testing one user is 100 percent better than testing none.** Always doing a live usability test at the beginning so that people can see that it's very easy to do and it always produced valuable insights.
- **Testing one user early in the project is better that testing 50 near the end.** Any mistakes you can correct early in the process will save you trouble down the line.

## Do-it-yourself usability testing

The basic idea of usability testing is pretty simple: if you want to know whether something is easy enough to use, watch some people they try to use it and note where they run into problems.

If you can't hire a professional to do the testing, do it yourself.

|   | Do-it-yourself testing |
| - | - |
| Time spent for each round of testing | One morning a month includes testing, debriefing, and deciding what to fix |
| When do you test? | Continually, throughout the development process |
| Number of rounds of testing | One every month |
| Number of participants in each round | Three |
| Now do you choose the participants? | Recruit loosely, if necessary. Doing frequent testing is more important that testing "actual" users |
| Where do you test? | On-site, with observers in a conference room using screen sharing software to watch |
| Who watches? | half day on-site testing means more people can see the test "live" |
| Reporting | A 1-2 page email summarizes decisions made during the team's debriefing |
| Who identifies the problems? | The entire development team and any interested stakeholders meet over lunch the same day to compare notes and decide what to fix |
| Primary purpose | Identify the most serious problems and commit to fixing them before the next round of testing |
Out-of-pocket costs | A few hundred dollars or less per round |

## How often should you test?

Development team should spend one morning a month (or every Sprint) doing usability testing.

In a morning, you can test three users, then debrief over lunch.

Why a morning a month?

- **It keeps it simple so you'll keep doing it.**
- **It gives you what you need.** Problems identification.
- **It frees you form deciding when to test.** Don't worry, there will always be *something* you can test each month.
- **It make it more likely that people will attend.**

## How many users do you need?

The ideal number of participants for each round is three:

- **The purpose of this kind of testing isn't to *prove* anything.** Proving things requires *quantitative* testing. Do-it-yourself tests are a qualitative method whose purpose is to *improve* things you do by identifying and fixing usability problems. The result is actionable insights, not proof.
- **You don't need to find all of the problems.** *You can find more problems in a half a day than you can fix in a month.* So it's important to focus on fixing the most serious ones first.

## How do you choose the participants?

Recruiting people who are from your target audience isn't so important.

**Recruit loosely and grade on a curve**

Loosen up your requirements and then make allowances for the difference between your participants and your audience.

You can recruit *some* people with required domain knowledge and some who *aren't* from your target audience:

- **It's usually not a good idea to design a site so that only your target audience can use it.**
- **We're all beginners under the skin.**
- **Experts are rarely insulted by something that is clear enough for beginners.** Everybody appreciates clarity.

## How do you find participants?

Places and ways to recruit test participants:

- user groups
- trade shows
- Craigslist
- Facebook
- Twitter
- customer forums
- a pop-up on your site
- asking friends and neighbors

If you're going to do your own recruiting, read report [How to recruit participants for usability studies](https://media.nngroup.com/media/reports/free/How_To_Recruit_Participants_for_Usability_Studies.pdf)

Typical participant incentives for a one-hour test session range from 50$ to 100$ for "average" Web users to several hundred dollars for highly paid professionals.

## Where do your test?

You need a quiet space with a table and two chairs, And you'll need a computer with Internet access, a mouse, a keyboard, and a microphone.

You'll be using screen sharing software to allow the team members to observe the tests from another room.

You should also run screen recording software to capture a record stuff from the screen and speech of the facilitator and the participant.

## Who should do the testing?

The person who sits with the participant and leads them through the test is called the facilitator.

Other than keeping the participants comfortable and focused on doing the tasks, the facilitator's main job is to encourage them to think out loud as much as possible.

## Who should observe?

As many people as possible.

It can be a transformative experience for involved stakeholders.

During the break after each test session, observers need to write down the *three* most serious usability problems they noticed during that session so they can share them in the debriefing.

It's important to make the list short as the purpose of the debriefing is to identify the most serious problems.

## What do you test, and then do you test it?



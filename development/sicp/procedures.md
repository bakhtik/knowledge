# Procedures and the Processes They Generate

We have now considered the elements of programming:

- primitive expressions
- combination of the expressions
- abstracting of the composite operations using compound procedures

But we still lack of knowledge:

- common patterns of usage
- of which procedures are worth defining
- to predict the consequences of executing a procedure

The ability to visualize the consequences of the actions under consideration is crucial to become an expert programmer.

To become experts, we must learn to visualize the processes generated by various types of procedures. Only after we have developed such a skill can we learn to reliably construct programs that exhibit the desired behavior.

A procedure is a pattern for the *local evolution* of a computational process. It specifies how each stage of the process is built upon the previous stage. We would like to be able to make statements about the overall, or *global*, behavior of a process whose local evolution has been specified by a procedure.

We will examine some common "shapes" for processes generated by simple procedures and will see how these processes consume computational resources of time and space.

## Linear Recursion and Iteration

We begin by considering the factorial function, defined by 

```
n! = n*(n - 1)*(n - 2) ... 3*2*1
```

One way to compute factorials is to make use of the observation that

```
n! = n*(n - 1)!
```

If we add stipulation that `1! = 1`, then we can translate this directly into a procedure:

```lisp
(define (factorial n)
  (if (= n 1)
    1
    (* n (factorial (- n 1)))))
```

We can use the substitution model to watch this procedure in action:

![factorial](img/factorial.png)

Now let's take a different perspective on computing factorials. We multiply 1 by 2, then multiply the result by 3, and so on until we reach *n*. More formally, we maintain a running product, together with a counter that counts from 1 up to *n*.

```lisp
(define (factorial n)
  (fact-iter 1 1 n))

(define (fact-iter product counter max-count)
  (if (> counter max-count)
    product
    (fact-iter (* counter product) (+ counter 1) max-count)))
```

We can use the substitution model to visualize the process of computing 6!:

![factorial 2](img/factorial2.png)

Compare the two processes.

They similar in

- compute same mathematical function
- number of steps proportional to *n*
- carry out the same sequence of multiplications

But when we consider the "shapes" of the two processes, we can see that they evolve differently.

Consider the first process. We can see a shape of expansion followed by contraction.

- The expansion occurs as the process builds up a chain of *deferred operations* (chain of multiplications).
- The contraction occurs as the operations are actually performed.

This type of process, characterized by a chain of deferred operations, is called a *recursive process*. Carrying out this process requires that the interpreter keep track of the operations to be performed later on.

In the computation of *n*!, the length of the chain of deferred multiplications, and hence the amount of information needed to keep track of it, grows linearly with *n*., just like the number of steps. Such a process is called a *linear recursive process*.

By contrast, the second process does not grow and shrink. At each step, all we need to keep track of, for any *n*, are the current values of the variables `product`, `counter`, and `max-count`. We call this an *iterative process*.

In general, an iterative process is one whose state can be summarized by a fixed number of *state variables*, together with a fixed rule that describes how the state variables should be updated as the process moves from state to state and an (optional) end test that specifies conditions under which the process should terminate.

In computing *n*!, the number of steps grows linearly with *n*. Such a process is called a *linear iterative process*.

In the iterative case, the program variables provide a complete description of the state of the process at any point.

In the case of recursive process there is some additional "hidden" information, maintained by the interpreter and not contained in the program variables, which indicates "where the process is" in negotiating the chain of deferred operations. The longer the chain, the more information must be maintained.

We must not to confuse the notion of a recursive *process* with the notion of a recursive *procedure*.

- Recursive procedure: we are referring to the syntactic fact that the procedure definition refers (either directly or indirectly) to the procedure itself.
- Recursive process: are are speaking about how the process evolves.

Most implementations of common languages (including C) are designed in such a way that the interpretation of any recursive procedure consumes an amount of memory that grows with the number of procedure calls, even when the process described is, in principle, iterative. As s consequence, these languages can describe iterative process only by using special-purpose "looping constructs" such ad `for` and `while`.

The implementation of Scheme does not share this defect. It will execute an iterative process in constant space, even if the iterative process is described by a recursive procedure. An implementation with this property is called *tail-recursive*.

## Tree Recursion

